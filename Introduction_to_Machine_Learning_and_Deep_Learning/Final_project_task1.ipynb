{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import metrics\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import activations\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.applications import InceptionResNetV2\n",
    "from tensorflow.keras.applications import Xception\n",
    "from tensorflow.keras.applications import VGG19\n",
    "from tensorflow.keras.applications import InceptionV3\n",
    "from tensorflow.keras.applications import NASNetLarge\n",
    "from tensorflow.keras.applications import ResNet50V2\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import regularizers\n",
    "from sklearn.utils import shuffle\n",
    "import shutil\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "def organize_datasets(original_path, ratio=0.2):\n",
    "    target_path_1 = '/content/drive/My Drive/Colab Notebooks/train'\n",
    "    target_path_2 = '/content/drive/My Drive/Colab Notebooks/validation'\n",
    "    reader = pd.read_csv('/content/drive/My Drive/Colab Notebooks/train.csv')\n",
    "    train_df = pd.DataFrame(reader)\n",
    "    shuffle(train_df)\n",
    "    n = 160\n",
    "    val = train_df[:n]\n",
    "    train = train_df[n:]\n",
    "    for row in train.iloc[:,0]:\n",
    "        if os.path.exists(target_path_1) :\n",
    "            full_path = os.path.join(original_path, row)\n",
    "            if os.path.exists(full_path):\n",
    "                shutil.copy(full_path,target_path_1)\n",
    "        else :\n",
    "            os.makedirs(target_path_1)\n",
    "            full_path = os.path.join(original_path, row)\n",
    "            if os.path.exists(full_path):\n",
    "                shutil.copy(full_path,target_path_1)\n",
    "    for row in val.iloc[:,0]:\n",
    "        if os.path.exists(target_path_2) :\n",
    "            full_path = os.path.join(original_path, row)\n",
    "            shutil.copy(full_path,target_path_2)\n",
    "        else :\n",
    "            os.makedirs(target_path_2)\n",
    "            full_path = os.path.join(original_path, row)\n",
    "            shutil.copy(full_path,target_path_2)\n",
    "\n",
    "    target_path = '/content/drive/My Drive/Colab Notebooks/test'\n",
    "    reader = pd.read_csv('/content/drive/My Drive/Colab Notebooks/testName.csv')\n",
    "    test_df = pd.DataFrame(reader)\n",
    "    for row in test_df.iloc[:,0]:\n",
    "        if os.path.exists(target_path) :\n",
    "            full_path = os.path.join(original_path, row)\n",
    "            if os.path.exists(full_path):\n",
    "                shutil.copy(full_path,target_path)\n",
    "        else :\n",
    "            os.makedirs(target_path)\n",
    "            full_path = os.path.join(original_path, row)\n",
    "            if os.path.exists(full_path):\n",
    "                shutil.copy(full_path,target_path)          \n",
    "    return train, val, test_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training images from Google drive directories\n",
    "\n",
    "trdf, vadf, tedf = organize_datasets('/content/drive/My Drive/Colab Notebooks/totalDepthPic')\n",
    "base_dir = '/content/drive/My Drive/Colab Notebooks'\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "columns=['Total rebars']\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1./255,\n",
    "                             horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "train_generator = datagen.flow_from_dataframe(trdf, train_dir, x_col='Pic Name', y_col=columns, \n",
    "                                              target_size=(150, 150), batch_size=30, class_mode='other')\n",
    "validation_generator = test_datagen.flow_from_dataframe(vadf, validation_dir, x_col='Pic Name', y_col=columns,\n",
    "                                                        target_size=(150, 150), batch_size=20, class_mode='other')\n",
    "test_generator = test_datagen.flow_from_dataframe(tedf, test_dir, x_col='Pic Name',\n",
    "                                                  batch_size=1, shuffle=False, class_mode=None, target_size=(150, 150))\n",
    "STEP_SIZE_TRAIN=40\n",
    "STEP_SIZE_VALID=20\n",
    "STEP_SIZE_TEST=test_generator.n//test_generator.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pretrained model: InceptionV3 with random initialization\n",
    "\n",
    "conv_base1 = InceptionV3(include_top=False, input_shape=(150, 150, 3), weights=None,)\n",
    "model1 = models.Sequential()\n",
    "model1.compile(optimizer='Adam', loss='mean_squared_error', metrics=[metrics.mae])\n",
    "model1.add(conv_base1)\n",
    "model1.add(layers.Flatten())\n",
    "model1.add(layers.Dropout(0.5))\n",
    "model1.add(layers.Dense(16, kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model1.add(layers.Dense(1, activation='linear'))\n",
    "\n",
    "# Train model\n",
    "history = model1.fit_generator(generator=train_generator, \n",
    "                               steps_per_epoch=STEP_SIZE_TRAIN, \n",
    "                               validation_data=validation_generator, \n",
    "                               validation_steps=STEP_SIZE_VALID, \n",
    "                               epochs=30)\n",
    "model1.save('/content/drive/My Drive/Colab Notebooks/model1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pretrained model: InceptionV3 with pre-training on ImageNet\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "conv_base2 = Xception(include_top=False, input_shape=(150, 150, 3))\n",
    "model2 = models.Sequential()\n",
    "model2.compile(optimizer='Adam', oss='mean_squared_error', metrics=[metrics.mae])\n",
    "model2.add(conv_base2)\n",
    "model2.add(layers.Flatten())\n",
    "model2.add(layers.Dropout(0.5))\n",
    "model2.add(layers.Dense(16, kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model2.add(layers.Dense(1, activation='linear'))\n",
    "\n",
    "model2.fit_generator(generator=train_generator, \n",
    "                     steps_per_epoch=STEP_SIZE_TRAIN, \n",
    "                     validation_data=validation_generator, \n",
    "                     validation_steps=STEP_SIZE_VALID, \n",
    "                     epochs=30)\n",
    "model2.save('/content/drive/My Drive/Colab Notebooks/model2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pretrained model: VGG19\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1./255, vertical_flip=True, horizontal_flip=True)\n",
    "\n",
    "conv_base3 = VGG19(include_top=False, input_shape=(150, 150, 3))\n",
    "model3 = models.Sequential()\n",
    "model3.compile(optimizer='Adam', \n",
    "              loss='mean_squared_error', \n",
    "              metrics=[metrics.mae])\n",
    "model3.add(conv_base3)\n",
    "model3.add(layers.Flatten())\n",
    "model3.add(layers.Dropout(0.5))\n",
    "model3.add(layers.Dense(16, kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model3.add(layers.Dense(1, activation='linear'))\n",
    "\n",
    "model3.fit_generator(generator=train_generator, \n",
    "                     steps_per_epoch=STEP_SIZE_TRAIN, \n",
    "                     validation_data=validation_generator, \n",
    "                     validation_steps=STEP_SIZE_VALID, \n",
    "                     epochs=30)\n",
    "model3.save('/content/drive/My Drive/Colab Notebooks/model3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pretrained model: ResNet50V2\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1./255, vertical_flip=True)\n",
    "\n",
    "conv_base4 = ResNet50V2(include_top=False, input_shape=(150, 150, 3))\n",
    "model4 = models.Sequential()\n",
    "model4.compile(optimizer='Adam', \n",
    "              loss='mean_squared_error', \n",
    "              metrics=[metrics.mae])\n",
    "model4.add(conv_base4)\n",
    "model4.add(layers.Flatten())\n",
    "model4.add(layers.Dropout(0.5))\n",
    "model4.add(layers.Dense(16, kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model4.add(layers.Dense(1, activation='linear'))\n",
    "\n",
    "model4.fit_generator(generator=train_generator, \n",
    "                     steps_per_epoch=STEP_SIZE_TRAIN, \n",
    "                     validation_data=validation_generator, \n",
    "                     validation_steps=STEP_SIZE_VALID, \n",
    "                     epochs=30)\n",
    "model4.save('/content/drive/My Drive/Colab Notebooks/model4.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pretrained model: InceptionResNetV2\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "conv_base5 = InceptionResNetV2(include_top=False, input_shape=(150, 150, 3))\n",
    "model5 = models.Sequential()\n",
    "model5.compile(optimizer='Adam', \n",
    "              loss='mean_squared_error', \n",
    "              metrics=[metrics.mae])\n",
    "model5.add(conv_base5)\n",
    "model5.add(layers.Flatten())\n",
    "model5.add(layers.Dropout(0.5))\n",
    "model5.add(layers.Dense(16, kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model5.add(layers.Dense(1, activation='linear'))\n",
    "\n",
    "model5.fit_generator(generator=train_generator, \n",
    "                     steps_per_epoch=STEP_SIZE_TRAIN, \n",
    "                     validation_data=validation_generator, \n",
    "                     validation_steps=STEP_SIZE_VALID, \n",
    "                     epochs=30)\n",
    "model5.save('/content/drive/My Drive/Colab Notebooks/model5.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pretrained model: NASNetLarge with random initialization\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1./255, vertical_flip=True, horizontal_flip=True)\n",
    "\n",
    "conv_base6 = NASNetLarge(include_top=False, input_shape=(150, 150, 3), weights=None)\n",
    "model6 = models.Sequential()\n",
    "model6.compile(optimizer='Adam', \n",
    "              loss='mean_squared_error', \n",
    "              metrics=[metrics.mae])\n",
    "model6.add(conv_base6)\n",
    "model6.add(layers.Flatten())\n",
    "model6.add(layers.Dropout(0.5))\n",
    "model6.add(layers.Dense(16, kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
    "model6.add(layers.Dense(1, activation='linear'))\n",
    "\n",
    "model6.fit_generator(generator=train_generator, \n",
    "                     steps_per_epoch=STEP_SIZE_TRAIN, \n",
    "                     validation_data=validation_generator, \n",
    "                     validation_steps=STEP_SIZE_VALID, \n",
    "                     epochs=30)\n",
    "model6.save('/content/drive/My Drive/Colab Notebooks/model6.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "\n",
    "STEP_SIZE_TRAIN=100\n",
    "STEP_SIZE_VALID=50\n",
    "STEP_SIZE_TEST=test_generator.n//test_generator.batch_size\n",
    "\n",
    "model1 = models.load_model('/content/drive/My Drive/Colab Notebooks/model1.h5')\n",
    "test_generator.reset()\n",
    "pred = model1.predict_generator(test_generator, steps=STEP_SIZE_TEST, verbose=2)\n",
    "predictions = pred\n",
    "results1=pd.DataFrame(predictions, columns=columns)\n",
    "results1[\"Pic Name\"] = test_generator.filenames\n",
    "ordered_cols = [\"Pic Name\"] + columns\n",
    "results1 = results1[ordered_cols]\n",
    "\n",
    "model2 = models.load_model('/content/drive/My Drive/Colab Notebooks/model2.h5')\n",
    "test_generator.reset()\n",
    "pred = model2.predict_generator(test_generator, steps=STEP_SIZE_TEST, verbose=2)\n",
    "predictions = pred\n",
    "results2=pd.DataFrame(predictions, columns=columns)\n",
    "results2[\"Pic Name\"] = test_generator.filenames\n",
    "ordered_cols = [\"Pic Name\"] + columns\n",
    "results2 = results2[ordered_cols]\n",
    "\n",
    "model3 = models.load_model('/content/drive/My Drive/Colab Notebooks/model3.h5')\n",
    "test_generator.reset()\n",
    "pred = model3.predict_generator(test_generator, steps=STEP_SIZE_TEST, verbose=2)\n",
    "predictions = pred\n",
    "results3=pd.DataFrame(predictions, columns=columns)\n",
    "results3[\"Pic Name\"] = test_generator.filenames\n",
    "ordered_cols = [\"Pic Name\"] + columns\n",
    "results3 = results3[ordered_cols]\n",
    "\n",
    "model4 = models.load_model('/content/drive/My Drive/Colab Notebooks/model4.h5')\n",
    "test_generator.reset()\n",
    "pred = model4.predict_generator(test_generator, steps=STEP_SIZE_TEST, verbose=2)\n",
    "predictions = pred\n",
    "results4=pd.DataFrame(predictions, columns=columns)\n",
    "results4[\"Pic Name\"] = test_generator.filenames\n",
    "ordered_cols = [\"Pic Name\"] + columns\n",
    "results4 = results4[ordered_cols]\n",
    "\n",
    "model5 = models.load_model('/content/drive/My Drive/Colab Notebooks/model5.h5')\n",
    "test_generator.reset()\n",
    "pred = model5.predict_generator(test_generator, steps=STEP_SIZE_TEST, verbose=2)\n",
    "predictions = pred\n",
    "results5=pd.DataFrame(predictions, columns=columns)\n",
    "results5[\"Pic Name\"] = test_generator.filenames\n",
    "ordered_cols = [\"Pic Name\"] + columns\n",
    "results5 = results5[ordered_cols]\n",
    "\n",
    "model6 = models.load_model('/content/drive/My Drive/Colab Notebooks/model6.h5')\n",
    "test_generator.reset()\n",
    "pred = model6.predict_generator(test_generator, steps=STEP_SIZE_TEST, verbose=2)\n",
    "predictions = pred\n",
    "results6=pd.DataFrame(predictions, columns=columns)\n",
    "results6[\"Pic Name\"] = test_generator.filenames\n",
    "ordered_cols = [\"Pic Name\"] + columns\n",
    "results6 = results6[ordered_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensemble\n",
    "\n",
    "re = []\n",
    "for i in range(len(results1.iloc[:,0])):\n",
    "    a = results1.iloc[i,-1] \n",
    "    b = results2.iloc[i,-1]\n",
    "    c = results3.iloc[i,-1]\n",
    "    d = results4.iloc[i,-1]\n",
    "    e = results5.iloc[i,-1]\n",
    "    f = results6.iloc[i,-1]\n",
    "    number = round(((a+b+c+d+e+f)/6))\n",
    "    re.append(number)\n",
    "results=pd.DataFrame(re, columns=columns)\n",
    "results[\"Pic Name\"] = test_generator.filenames\n",
    "ordered_cols = [\"Pic Name\"] + columns\n",
    "results = results[ordered_cols]\n",
    "results.to_csv('/content/drive/My Drive/Colab Notebooks/results.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
